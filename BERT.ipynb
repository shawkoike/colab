{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwIduNt2aqunQkVijTZjpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawkoike/colab/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9J3j7xgAjiQ",
        "outputId": "5585de67-ab43-4d76-fdc4-60ad9b859f59"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLZ8-LXkA-g-",
        "outputId": "868e73c0-c11a-405e-b5c6-ed65de86b235"
      },
      "source": [
        "!pip install fugashi ipadic"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 211 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=2911f15d6d5ce9eadeb043d17b235996275e7126365d74bdbfbf1feb3385da25\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic\n",
            "Successfully installed ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0D19gtcAu0Z",
        "outputId": "510a70f0-8757-4c2b-f532-bc732de25461"
      },
      "source": [
        "from transformers import BertJapaneseTokenizer, BertModel, BertForSequenceClassification\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "model_bert = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "model_bert.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3q4azCNAzA1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def calc_embedding(text):\n",
        "  bert_tokens = tokenizer.tokenize(text)\n",
        "  ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + bert_tokens[:126] + [\"[SEP]\"])\n",
        "  tokens_tensor = torch.tensor(ids).reshape(1, -1)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model_bert(tokens_tensor)\n",
        "\n",
        "  return output[1].numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaLDo1M6BheF",
        "outputId": "242b9875-ebcc-42e9-d789-760e9d0a7534"
      },
      "source": [
        "import torch\n",
        "\n",
        "text = '弊社では、正社員＆業務委託両方エンジニアのマネジメントに関してのアドバイスや、壁打ちをしていただける方を募集しております。'\n",
        "calc_embedding(text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.42562583e-02, -4.87308860e-01, -3.20419014e-01,\n",
              "        -4.71766233e-01,  4.92970198e-01,  9.90663826e-01,\n",
              "        -2.56614447e-01, -2.07270890e-01, -6.00988150e-01,\n",
              "         6.44050479e-01,  6.58983469e-01,  4.72109437e-01,\n",
              "         1.38158441e-01, -1.55992299e-01, -9.13974494e-02,\n",
              "        -2.64104307e-01,  2.20058322e-01, -1.71948463e-01,\n",
              "         5.14209747e-01,  2.41091028e-01,  4.64216053e-01,\n",
              "         3.67626220e-01, -4.52453315e-01,  9.92384017e-01,\n",
              "         9.97700691e-01, -1.96783930e-01,  3.83341074e-01,\n",
              "        -1.86367199e-01,  9.97067809e-01,  6.34538174e-01,\n",
              "        -1.62623882e-01,  7.53186703e-01,  1.06818900e-01,\n",
              "         2.94518292e-01,  3.43914539e-01,  2.36771360e-01,\n",
              "         2.71752596e-01, -5.16558409e-01, -3.95080447e-01,\n",
              "        -9.65224802e-02,  2.66385734e-01, -9.86554623e-01,\n",
              "        -6.24001324e-01,  3.36041510e-01,  3.33483040e-01,\n",
              "        -1.93969786e-01,  5.54513156e-01, -2.88166046e-01,\n",
              "        -2.62332201e-01, -2.87782460e-01,  4.45849568e-01,\n",
              "        -6.56644285e-01,  2.24138163e-02, -9.99917388e-01,\n",
              "        -4.66299593e-01, -6.11620508e-02, -1.75393507e-01,\n",
              "        -4.84530091e-01, -1.78754404e-01,  8.82339895e-01,\n",
              "         6.92143142e-01,  8.98491621e-01,  4.40075785e-01,\n",
              "         4.52053785e-01,  3.30013424e-01,  2.98618555e-01,\n",
              "         1.78650022e-01,  2.76649624e-01,  3.46887320e-01,\n",
              "         8.94782782e-01, -4.31336582e-01,  6.38396293e-02,\n",
              "        -5.06773829e-01,  5.49652040e-01,  2.59553492e-01,\n",
              "         3.76814753e-02,  9.92801249e-01,  3.57788913e-02,\n",
              "         9.64122415e-01,  1.16178796e-01, -7.40861177e-01,\n",
              "        -7.86361918e-02, -4.09214616e-01,  2.85162568e-01,\n",
              "        -9.42216694e-01,  2.98156559e-01, -4.08693582e-01,\n",
              "         5.66713922e-02,  3.42588425e-01, -8.69624674e-01,\n",
              "         3.69440675e-01, -8.85651469e-01,  3.04937512e-01,\n",
              "        -2.68822014e-01, -2.60254681e-01,  2.31069908e-01,\n",
              "        -1.39234439e-01,  3.85408580e-01, -5.87654591e-01,\n",
              "         6.04182184e-01,  2.91309267e-01,  3.36016446e-01,\n",
              "        -1.78726137e-01,  3.86007965e-01,  4.28428471e-01,\n",
              "         1.59711510e-01, -5.01469076e-01,  3.61032814e-01,\n",
              "        -4.41351771e-01, -1.39183566e-01,  4.11287665e-01,\n",
              "        -2.27326289e-01,  1.54076606e-01, -4.72888798e-01,\n",
              "         3.30571793e-02,  1.75702229e-01, -2.37699836e-01,\n",
              "        -3.56779605e-01,  1.53097406e-01,  1.68250531e-01,\n",
              "         2.12047711e-01, -2.80049682e-01,  1.13062195e-01,\n",
              "        -2.67623335e-01, -8.81342471e-01, -9.94932473e-01,\n",
              "        -2.10444912e-01, -3.89127910e-01,  2.50652641e-01,\n",
              "        -3.61591309e-01,  2.80192167e-01,  6.27493262e-02,\n",
              "         3.04107964e-01,  2.09680662e-01, -1.19152166e-01,\n",
              "        -2.55527347e-01,  3.28838639e-02,  2.11086959e-01,\n",
              "         2.68985983e-03,  6.99716091e-01, -5.09068847e-01,\n",
              "        -6.27320290e-01,  2.44091183e-01,  2.24690035e-01,\n",
              "        -9.97527301e-01,  3.17554593e-01, -2.61749119e-01,\n",
              "         3.16379696e-01, -1.41625524e-01,  3.98063213e-01,\n",
              "        -2.08514705e-01,  1.62112266e-01, -5.53783588e-02,\n",
              "        -4.69485283e-01,  1.08520024e-01,  5.35078526e-01,\n",
              "         5.08955359e-01, -2.40842760e-01, -3.94873381e-01,\n",
              "        -6.33976579e-01, -4.94952500e-01,  6.54605478e-02,\n",
              "        -3.05309534e-01, -6.13152623e-01, -1.93791255e-01,\n",
              "         4.67043892e-02, -5.07836640e-01,  2.85251945e-01,\n",
              "         9.61713076e-01,  9.10200536e-01,  2.73698628e-01,\n",
              "         5.29225767e-01,  1.75267935e-01,  6.17725179e-02,\n",
              "         1.53107613e-01,  5.66473305e-01, -5.58612607e-02,\n",
              "        -2.02207014e-01,  8.41985703e-01,  1.31445721e-01,\n",
              "        -5.51967770e-02,  4.05041307e-01,  4.98455584e-01,\n",
              "        -2.36546844e-01, -4.89909314e-02,  4.57236230e-01,\n",
              "        -2.11553872e-01, -3.05311531e-01, -8.00258994e-01,\n",
              "        -1.08773177e-02,  2.37496287e-01,  8.67360234e-01,\n",
              "        -3.08468610e-01, -3.47699702e-01, -1.07623935e-01,\n",
              "        -1.52107581e-01, -2.71087974e-01,  3.08167189e-01,\n",
              "         1.48245305e-01,  9.43369806e-01, -7.82590806e-01,\n",
              "        -2.40301609e-01,  1.13369144e-01,  3.63591224e-01,\n",
              "        -4.89687145e-01, -3.62118393e-01, -9.90661502e-01,\n",
              "         4.59777176e-01, -8.19008648e-02,  2.07349330e-01,\n",
              "        -4.21928853e-01, -5.47871709e-01,  7.69985557e-01,\n",
              "         7.44382143e-01,  9.84842300e-01, -1.67108133e-01,\n",
              "        -4.20478463e-01,  1.41546100e-01,  4.71917599e-01,\n",
              "        -1.28266364e-01, -3.31140757e-01,  8.72551799e-01,\n",
              "         6.45996749e-01,  3.36656928e-01, -3.57441843e-01,\n",
              "         3.06353241e-01, -1.43935442e-01,  8.38098824e-01,\n",
              "        -2.56283253e-01,  9.17650878e-01,  9.45987642e-01,\n",
              "        -2.40727365e-01,  1.62664071e-01, -1.82878405e-01,\n",
              "        -2.80646086e-01,  3.86873335e-01, -2.25345641e-01,\n",
              "         7.81981573e-02,  2.03682929e-01, -2.41272643e-01,\n",
              "         1.29149556e-01,  1.03569053e-01,  5.21450102e-01,\n",
              "         9.98473465e-01, -1.53032660e-01,  3.92142326e-01,\n",
              "         3.91965181e-01, -5.77008069e-01, -2.69065619e-01,\n",
              "         3.01961571e-01, -9.97930706e-01,  3.46195661e-02,\n",
              "         3.86907876e-01,  1.26951411e-01, -3.46075475e-01,\n",
              "         5.74049577e-02,  9.97573316e-01, -5.52060604e-01,\n",
              "         9.94753122e-01, -1.25461459e-01,  3.62517893e-01,\n",
              "        -8.69215786e-01, -2.39738360e-01, -5.10099418e-02,\n",
              "         9.96438920e-01,  1.79561421e-01, -6.12507761e-03,\n",
              "        -4.67270851e-01,  3.27440709e-01,  9.88791108e-01,\n",
              "         4.00740564e-01,  1.62235480e-02, -8.92422944e-02,\n",
              "        -1.41874999e-01, -4.27286893e-01,  3.06389332e-01,\n",
              "        -4.47595388e-01, -5.80438018e-01, -9.42005873e-01,\n",
              "        -4.60524619e-01,  2.37241879e-01, -1.17075026e-01,\n",
              "        -3.18158388e-01,  9.94152963e-01,  3.58199239e-01,\n",
              "        -3.41112792e-01, -5.09009123e-01, -1.28647303e-02,\n",
              "        -4.31093037e-01, -9.95870411e-01,  8.97542417e-01,\n",
              "        -4.14765775e-01, -4.18982148e-01,  3.30614895e-01,\n",
              "        -2.29409859e-01, -7.05694035e-02,  3.84021193e-01,\n",
              "        -5.94115853e-01,  3.66435088e-02,  9.58875299e-01,\n",
              "         4.10175264e-01, -8.59820902e-01,  4.11391973e-01,\n",
              "         4.45209444e-01, -1.06018312e-01,  5.43631852e-01,\n",
              "        -9.97245789e-01, -3.60055298e-01, -2.99138904e-01,\n",
              "        -9.93571937e-01,  3.63065004e-01, -1.82772856e-02,\n",
              "        -9.79008913e-01, -9.50062811e-01, -4.51306015e-01,\n",
              "        -4.36544716e-01, -5.40767968e-01,  1.05373889e-01,\n",
              "        -4.79518056e-01,  3.52845520e-01, -2.43247405e-01,\n",
              "        -1.16335884e-01,  9.88156319e-01, -3.93260807e-01,\n",
              "        -2.04369277e-01, -4.11931187e-01,  2.65523463e-01,\n",
              "         5.27690053e-02,  6.18208237e-02,  1.09818257e-01,\n",
              "         1.64764211e-01,  3.85522731e-02,  3.42264533e-01,\n",
              "         9.17634368e-02, -3.44184935e-01,  4.63870108e-01,\n",
              "         1.60020769e-01, -1.50360808e-01, -3.52258235e-01,\n",
              "        -5.08447662e-02,  4.26993132e-01, -8.70122015e-01,\n",
              "        -4.36920524e-01, -3.17315638e-01,  3.65799755e-01,\n",
              "         1.25293098e-02, -9.22098756e-02, -3.16174120e-01,\n",
              "        -1.93082735e-01, -2.68844292e-02, -2.90193528e-01,\n",
              "        -3.56672019e-01,  2.89711595e-01, -3.87731075e-01,\n",
              "        -3.48492861e-01,  3.58335257e-01,  4.15159792e-01,\n",
              "         4.08967704e-01, -6.12925887e-01,  2.87039161e-01,\n",
              "        -5.22791684e-01,  9.84233618e-01, -9.21691805e-02,\n",
              "        -2.90008932e-01, -9.97382939e-01,  9.84598994e-01,\n",
              "        -3.54436070e-01, -1.88294739e-01, -6.93382472e-02,\n",
              "         1.28348634e-01,  1.45926490e-01, -3.54982197e-01,\n",
              "         4.88944083e-01,  8.21300447e-02,  4.83994395e-01,\n",
              "        -6.92266464e-01,  9.13447976e-01, -3.27326328e-01,\n",
              "        -3.12199801e-01,  9.96440470e-01, -2.98470892e-02,\n",
              "         3.53304386e-01,  1.69028208e-01,  3.92507970e-01,\n",
              "        -4.36758637e-01, -9.66170013e-01, -4.87122834e-01,\n",
              "        -3.11045855e-01,  3.42828572e-01,  2.53463537e-01,\n",
              "        -3.05293143e-01,  6.69755220e-01, -2.52949148e-01,\n",
              "         2.19999522e-01, -2.79180408e-01,  4.91115957e-01,\n",
              "         1.30673200e-01,  1.50469944e-01, -4.76233624e-02,\n",
              "        -1.14002608e-01, -4.51878160e-01, -4.86251861e-01,\n",
              "         4.80503857e-01,  3.66009474e-01,  3.11791569e-01,\n",
              "        -9.54895914e-01, -4.74744111e-01, -4.12119687e-01,\n",
              "         1.57130674e-01, -1.09544754e-01,  3.46469790e-01,\n",
              "        -8.56057823e-01,  4.37329561e-01, -9.99752939e-01,\n",
              "         3.40377152e-01,  3.15465271e-01, -6.45355225e-01,\n",
              "        -9.99808311e-01,  2.31615409e-01,  4.15647298e-01,\n",
              "         1.52217448e-01,  4.67452407e-01, -2.09412634e-01,\n",
              "        -4.09630090e-01, -3.18847746e-01, -2.80789912e-01,\n",
              "         4.47492987e-01, -4.34516847e-01, -4.46983874e-01,\n",
              "         3.07481110e-01, -9.86454010e-01,  9.97314095e-01,\n",
              "        -5.40458441e-01, -6.39454722e-02,  2.05997348e-01,\n",
              "        -3.26006025e-01,  3.36401492e-01,  9.71370459e-01,\n",
              "        -2.92880267e-01,  5.98059535e-01, -5.75965703e-01,\n",
              "         3.43486696e-01, -1.04350224e-01,  6.25689089e-01,\n",
              "         3.57719451e-01, -5.86752594e-01,  7.85372794e-01,\n",
              "         8.23192596e-02, -1.50287509e-01,  1.34463504e-01,\n",
              "         9.79645312e-01,  3.96265358e-01,  3.32326531e-01,\n",
              "         6.18845522e-01,  1.52301148e-01, -3.68297845e-01,\n",
              "         4.87578183e-01,  1.79516468e-02, -4.61744726e-01,\n",
              "        -3.67226541e-01, -1.17957450e-01, -3.50639343e-01,\n",
              "         5.80096006e-01, -5.58369696e-01,  6.15982294e-01,\n",
              "         9.97247636e-01, -3.39284509e-01, -5.55564582e-01,\n",
              "         5.11344969e-01, -1.99142277e-01,  3.25159252e-01,\n",
              "        -6.14162624e-01, -2.27822274e-01,  3.44757736e-01,\n",
              "         1.20289624e-01, -2.13191196e-01,  2.04399794e-01,\n",
              "        -3.24741960e-01, -9.67242122e-01,  5.44798315e-01,\n",
              "        -9.62149203e-01,  8.79343510e-01,  1.47632986e-01,\n",
              "        -9.97848988e-01,  2.58713663e-01, -4.65059280e-01,\n",
              "         1.53156266e-01, -3.38829637e-01, -7.79036641e-01,\n",
              "        -4.67343450e-01,  9.99934077e-01, -2.07930326e-01,\n",
              "         4.80386317e-01, -3.84473443e-01,  3.67956638e-01,\n",
              "        -1.98139161e-01, -3.45126778e-01,  8.04422870e-02,\n",
              "         9.37856555e-01, -3.66034865e-01,  2.88774729e-01,\n",
              "        -9.96819317e-01, -8.59192252e-01,  3.47358942e-01,\n",
              "         6.06613398e-01, -4.79327738e-01, -1.86916336e-01,\n",
              "         3.53771657e-01, -3.32571447e-01, -9.87028182e-01,\n",
              "        -2.44978786e-01, -4.79389608e-01, -2.07108691e-01,\n",
              "         1.94995224e-01, -3.23970109e-01, -2.04873666e-01,\n",
              "        -4.35297847e-01, -5.42842634e-02, -6.30735978e-02,\n",
              "        -9.71110523e-01, -4.54643548e-01,  1.91511497e-01,\n",
              "        -4.40921366e-01,  9.88372445e-01, -8.09923589e-01,\n",
              "         4.91078764e-01, -9.09698606e-01, -1.67298317e-01,\n",
              "         9.87633646e-01,  4.24628705e-02,  9.73046124e-01,\n",
              "         5.65469861e-02, -4.48017120e-01, -9.99905705e-01,\n",
              "        -3.48802626e-01, -6.48753822e-01, -2.45957196e-01,\n",
              "        -7.46981055e-02, -2.72786319e-01,  4.58484590e-01,\n",
              "         4.37206447e-01,  5.32074571e-01, -1.76032975e-01,\n",
              "         4.69486266e-01, -3.64459246e-01,  9.97497141e-01,\n",
              "        -2.56349534e-01,  3.73331249e-01, -8.95273685e-01,\n",
              "        -4.28158998e-01, -7.25137591e-01, -3.78303438e-01,\n",
              "        -3.39465678e-01, -9.97390926e-01, -2.22912714e-01,\n",
              "         3.05804014e-01,  3.23944867e-01,  2.52757639e-01,\n",
              "        -1.76552758e-01, -5.95752656e-01, -4.89643633e-01,\n",
              "         5.01004517e-01,  1.99935868e-01,  7.33295339e-04,\n",
              "        -9.97748911e-01, -5.31208336e-01,  3.07211190e-01,\n",
              "        -5.31887889e-01,  4.04631227e-01, -4.39787120e-01,\n",
              "         4.09963131e-01,  1.40392661e-01, -8.63525689e-01,\n",
              "        -2.23456044e-02, -8.43362808e-01, -7.11192548e-01,\n",
              "         9.96496677e-01, -2.24082932e-01,  4.64914680e-01,\n",
              "        -1.70392796e-01,  2.04995424e-01, -3.66671205e-01,\n",
              "        -4.99273479e-01, -5.59990346e-01,  4.16167825e-01,\n",
              "         3.64767939e-01,  2.84924328e-01, -6.93967760e-01,\n",
              "         4.88814652e-01,  3.54365349e-01,  2.39669263e-01,\n",
              "        -5.41649818e-01,  3.55003953e-01, -7.62430906e-01,\n",
              "        -7.58816376e-02, -9.03998733e-01,  2.92622223e-02,\n",
              "        -1.88544318e-01,  4.25725073e-01,  4.06436950e-01,\n",
              "         5.79555258e-02,  9.97453451e-01,  5.08507013e-01,\n",
              "         9.87814128e-01,  4.98757303e-01,  7.27788210e-02,\n",
              "        -3.18509072e-01, -7.30678067e-02, -2.18827397e-01,\n",
              "         4.08920884e-01, -8.70253921e-01, -3.85459453e-01,\n",
              "         3.72372568e-01, -9.58672345e-01, -1.30305305e-01,\n",
              "        -9.60404515e-01, -4.63755965e-01,  3.45165670e-01,\n",
              "        -3.65729988e-01, -4.66589659e-01,  9.97747183e-01,\n",
              "         7.07834721e-01, -1.04556695e-01,  1.97028130e-01,\n",
              "        -2.08388999e-01, -8.06707516e-02, -5.84165633e-01,\n",
              "         1.57717630e-01, -2.74051934e-01, -3.01365614e-01,\n",
              "         3.21854770e-01,  5.95645308e-01, -4.83564973e-01,\n",
              "         3.67757916e-01,  8.00304592e-01, -3.33468497e-01,\n",
              "        -1.19265005e-01,  7.05899745e-02, -1.74660206e-01,\n",
              "         2.03954056e-01,  2.82074034e-01, -3.55483234e-01,\n",
              "        -2.16454983e-01, -1.64846838e-01, -3.90239477e-01,\n",
              "        -9.93165970e-01,  7.44708717e-01,  8.25035870e-01,\n",
              "         2.62072593e-01, -3.28425616e-01,  4.43213373e-01,\n",
              "         1.98598295e-01, -3.88363451e-01,  3.64222586e-01,\n",
              "        -9.99413669e-01, -4.85443115e-01,  2.66540229e-01,\n",
              "        -5.10700881e-01, -7.43287683e-01, -4.49691564e-02,\n",
              "         3.77858788e-01,  9.81299400e-01,  2.44128019e-01,\n",
              "         2.01015279e-01,  2.70675838e-01,  3.07765007e-01,\n",
              "        -3.81939173e-01, -3.85124296e-01,  2.38692611e-01,\n",
              "         1.40745655e-01, -7.80389924e-03, -2.70401567e-01,\n",
              "         3.61340374e-01,  9.79529858e-01, -4.99017313e-02,\n",
              "        -1.43850157e-02, -1.72908962e-01,  9.03008059e-02,\n",
              "         5.24939060e-01, -1.09976217e-01,  3.51753950e-01,\n",
              "         6.09672487e-01, -3.31498295e-01,  9.61935401e-01,\n",
              "        -4.41670805e-01, -1.93202734e-01,  1.83260694e-01,\n",
              "         3.37798089e-01,  3.84873897e-01,  4.17703658e-01,\n",
              "         8.94185603e-01,  8.73929203e-01, -1.66769266e-01,\n",
              "         1.61715567e-01,  2.85606116e-01,  1.86523512e-01,\n",
              "         3.71730238e-01,  2.82268554e-01,  2.48347506e-01,\n",
              "        -2.18373928e-02, -5.04746795e-01, -3.60033661e-01,\n",
              "         4.27008659e-01, -2.72998184e-01,  1.90355882e-01,\n",
              "         4.12312925e-01,  2.63436139e-01, -9.97645736e-01,\n",
              "        -3.34541619e-01, -5.58593810e-01, -3.86641249e-02,\n",
              "         3.26231867e-01,  9.99699950e-01,  4.92421567e-01,\n",
              "        -4.05769318e-01, -4.57559347e-01, -3.39503735e-01,\n",
              "         5.24351776e-01,  3.42456400e-01, -3.35976005e-01,\n",
              "        -3.00643235e-01,  1.10551819e-01, -1.43119186e-01,\n",
              "        -5.53295851e-01,  8.98891985e-02, -9.83640611e-01,\n",
              "         5.14383972e-01, -2.00504348e-01,  3.03210855e-01,\n",
              "        -1.90750927e-01,  4.38569039e-01, -8.26740980e-01,\n",
              "        -9.93248522e-01,  5.54912746e-01, -5.04549146e-02,\n",
              "         4.36670154e-01, -1.30993620e-01,  1.53045073e-01,\n",
              "        -3.82384211e-01, -2.63039112e-01,  9.91161466e-01,\n",
              "         1.96032986e-01,  5.34577593e-02,  4.37638938e-01,\n",
              "        -5.81239879e-01,  4.09965545e-01,  2.76275396e-01,\n",
              "         3.11357498e-01, -9.87355828e-01,  2.34215446e-02,\n",
              "         3.51856709e-01,  6.96779117e-02,  1.55792221e-01,\n",
              "         1.08002417e-01,  3.71988207e-01, -9.99568045e-01,\n",
              "         3.17525595e-01,  2.98786312e-01, -4.34571266e-01,\n",
              "         4.01860267e-01,  2.00005502e-01,  3.41880769e-01,\n",
              "        -4.81206477e-01,  5.25815129e-01, -1.25817060e-01,\n",
              "         3.37900817e-01,  2.98814774e-01, -4.54136491e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG5fGeJyNeUB",
        "outputId": "fcc86178-fdf8-4c28-9778-106053221b01"
      },
      "source": [
        "import torch\n",
        "\n",
        "text = '世界を目指すスタートアップで1人目の正社員募集(業務委託でもOK)'\n",
        "calc_embedding(text).shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jId6DpNgOnf6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}